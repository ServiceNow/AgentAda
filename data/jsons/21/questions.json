[
    {
        "cell_ids": [
            1,
            2
        ],
        "question": "What is the size of the dataset used for sentiment analysis, and how are the sentiment labels distributed?",
        "answer": "The dataset contains 40,000 reviews, evenly split between positive and negative sentiments.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    },
    {
        "cell_ids": [
            3,
            4,
            5
        ],
        "question": "What preprocessing steps are applied to the reviews before training the LSTM model?",
        "answer": "Preprocessing includes tokenization, converting text to sequences, and padding sequences to a fixed length of 100.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            6
        ],
        "question": "What embedding size is used in the LSTM model, and how does it impact performance?",
        "answer": "The embedding size is set to 128, which balances semantic representation and computational efficiency.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            7,
            8
        ],
        "question": "What accuracy does the LSTM model achieve on the test dataset?",
        "answer": "The LSTM model achieves 93% accuracy on the test dataset.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            9,
            10
        ],
        "question": "What types of reviews are most frequently misclassified by the LSTM model?",
        "answer": "Reviews with ambiguous or mixed sentiments are most frequently misclassified.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            11,
            12,
            13
        ],
        "question": "How does increasing the number of LSTM layers affect the model's performance?",
        "answer": "Adding more layers improves performance up to 2 layers, beyond which overfitting is observed.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            14,
            15
        ],
        "question": "What role does the dropout layer play in improving the generalization of the LSTM model?",
        "answer": "The dropout layer prevents overfitting by randomly deactivating neurons during training.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            16,
            17
        ],
        "question": "What are the most common words in reviews classified as positive sentiment?",
        "answer": "Words like 'amazing', 'excellent', and 'love' are frequently found in positive sentiment reviews.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    },
    {
        "cell_ids": [
            18,
            19
        ],
        "question": "How does varying the batch size affect the LSTM model's training time and accuracy?",
        "answer": "A batch size of 32 provides the best balance between training time and model accuracy.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            20,
            21,
            22
        ],
        "question": "What is the effect of review length on the accuracy of the LSTM model?",
        "answer": "The model performs best on reviews with lengths between 50 and 100 words, with reduced accuracy for very short or very long reviews.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    }
]
