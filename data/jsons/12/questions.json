[
    {
        "cell_ids": [
            1
        ],
        "question": "What is the size of the dataset used for detecting bullying tweets, and how are the labels distributed?",
        "answer": "The dataset contains 10,000 tweets, with 5,000 labeled as bullying and 5,000 labeled as non-bullying.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    },
    {
        "cell_ids": [
            3,
            4
        ],
        "question": "What preprocessing steps are applied to the tweets for this analysis?",
        "answer": "Preprocessing includes tokenizing the tweets using the BERT tokenizer, removing URLs and special characters, and padding sequences to a fixed length.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            5,
            6,
            7
        ],
        "question": "What is the maximum sequence length used during tokenization, and why was it chosen?",
        "answer": "The maximum sequence length is set to 128 to ensure computational efficiency while capturing enough context.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            8
        ],
        "question": "What evaluation metrics are used to assess the BERT model's performance in detecting bullying tweets?",
        "answer": "Metrics include accuracy, precision, recall, and F1-score.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            10,
            11
        ],
        "question": "What accuracy does the BERT model achieve on the validation dataset for detecting bullying tweets?",
        "answer": "The BERT model achieves an accuracy of 92% on the validation dataset.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            13,
            14
        ],
        "question": "What types of tweets are most frequently misclassified by the BERT model?",
        "answer": "Tweets containing sarcasm or mixed sentiments are most frequently misclassified.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            15,
            16,
            17
        ],
        "question": "What is the impact of increasing the number of fine-tuning epochs on the model's performance?",
        "answer": "The model achieves optimal performance after 4 epochs, with overfitting observed beyond this point.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            18,
            19,
            20
        ],
        "question": "How does the model's performance vary with the length of the tweets?",
        "answer": "The model performs better on tweets between 10 and 30 words, with accuracy dropping for very short or very long tweets.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            21,
            22
        ],
        "question": "What role does the learning rate play in optimizing the BERT model's performance?",
        "answer": "A learning rate of 3e-5 provides the best balance between convergence speed and performance.",
        "task": "Sentiment Analysis",
        "skill": "BERT"
    },
    {
        "cell_ids": [
            23,
            24,
            25,
            26
        ],
        "question": "What are the most common words or patterns in bullying tweets identified by the model?",
        "answer": "Words like 'stupid', 'idiot', and phrases with aggressive tones are common in bullying tweets.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    }
]
