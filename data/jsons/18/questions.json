[
    {
        "cell_ids": [
            1,
            2
        ],
        "question": "What is the size of the IMDB dataset used for sentiment analysis, and how are the sentiment labels distributed?",
        "answer": "The dataset contains 50,000 reviews, evenly split between positive and negative sentiments.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    },
    {
        "cell_ids": [
            3,
            4,
            5
        ],
        "question": "What preprocessing steps are applied to the reviews before training the LSTM model?",
        "answer": "Steps include tokenization, converting text to sequences, and padding or truncating to a fixed length of 200.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            6,
            7
        ],
        "question": "What embedding size is used in the LSTM model, and how does it impact performance?",
        "answer": "The embedding size is set to 128, providing a good balance between semantic representation and computational efficiency.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            8
        ],
        "question": "What accuracy does the LSTM model achieve on the test dataset?",
        "answer": "The LSTM model achieves 87% accuracy on the test dataset.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            9,
            10
        ],
        "question": "What types of reviews are most frequently misclassified by the LSTM model?",
        "answer": "Reviews with mixed sentiments or containing ambiguous tones are most frequently misclassified.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            11,
            12,
            13
        ],
        "question": "How does varying the number of LSTM layers impact the model's accuracy?",
        "answer": "Increasing the number of LSTM layers improves performance up to 2 layers, after which accuracy plateaus.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            14,
            15
        ],
        "question": "What role does the dropout rate play in preventing overfitting in the LSTM model?",
        "answer": "A dropout rate of 0.3 reduces overfitting and helps generalize the model to unseen data.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            16,
            17,
            18
        ],
        "question": "What are the most frequent words in reviews classified as positive sentiment?",
        "answer": "Words like 'amazing', 'great', and 'love' are frequently found in positive sentiment reviews.",
        "task": "Basic Data Analysis",
        "skill": "Basic Data Analysis"
    },
    {
        "cell_ids": [
            19,
            20
        ],
        "question": "How does the LSTM model's performance vary with different batch sizes?",
        "answer": "A batch size of 32 provides the best trade-off between training efficiency and model accuracy.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    },
    {
        "cell_ids": [
            21,
            22,
            23
        ],
        "question": "What is the effect of review length on the LSTM model's accuracy?",
        "answer": "The model performs better on reviews with lengths between 50 and 150 words, with reduced accuracy for shorter or longer reviews.",
        "task": "Sentiment Analysis",
        "skill": "LSTM"
    }
]
